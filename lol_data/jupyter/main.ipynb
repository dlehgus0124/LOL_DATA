{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased and revision 6ea8117 (https://huggingface.co/distilbert/distilbert-base-cased).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 관련 API를 호출합니다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Hugging Face pipeline으로 질문 분석\n",
    "question = \"탑 아트록스의 아이템은 뭐야?\"\n",
    "qa_pipeline = pipeline(\"feature-extraction\")  # 또는 custom tokenizer 사용\n",
    "keywords = [\"아이템\"]  # 우선적으로 찾을 키워드 리스트\n",
    "\n",
    "if any(keyword in question for keyword in keywords):\n",
    "    print(\"아이템 관련 API를 호출합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아트록스', '아리', '아칼리', '아크샨', '알리스타', '아무무', '애니비아', '애니', '아펠리오스', '애쉬', '아우렐리온 솔', '아지르', '바드', '벨베스', '블리츠크랭크', '브랜드', '브라움', '브라이어', '케이틀린', '카밀', '카시오페아', '초가스', '코르키', '다리우스', '다이애나', '드레이븐', '문도 박사', '에코', '엘리스', '이블린', '이즈리얼', '피들스틱', '피오라', '피즈', '갈리오', '갱플랭크', '가렌', '나르', '그라가스', '그레이브즈', '그웬', '헤카림', '하이머딩거', '흐웨이', '일라오이', '이렐리아', '아이번', '잔나', '자르반 4세', '잭스', '제이스', '진', '징크스', '카이사', '칼리스타', '카르마', '카서스', '카사딘', '카타리나', '케일', '케인', '케넨', '카직스', '킨드레드', '클레드', '코그모', '크산테', '르블랑', '리 신', '레오나', '릴리아', '리산드라', '루시안', '룰루', '럭스', '말파이트', '말자하', '마오카이', '마스터 이', '밀리오', '미스 포츈', '오공', '모데카이저', '모르가나', '나피리', '나미', '나서스', '노틸러스', '니코', '니달리', '닐라', '녹턴', '누누와 윌럼프', '올라프', '오리아나', '오른', '판테온', '뽀삐', '파이크', '키아나', '퀸', '라칸', '람머스', '렉사이', '렐', '레나타 글라스크', '레넥톤', '렝가', '리븐', '럼블', '라이즈', '사미라', '세주아니', '세나', '세라핀', '세트', '샤코', '쉔', '쉬바나', '신지드', '사이온', '시비르', '스카너', '스몰더', '소나', '소라카', '스웨인', '사일러스', '신드라', '탐 켄치', '탈리야', '탈론', '타릭', '티모', '쓰레쉬', '트리스타나', '트런들', '트린다미어', '트위스티드 페이트', '트위치', '우디르', '우르곳', '바루스', '베인', '베이가', '벨코즈', '벡스', '바이', '비에고', '빅토르', '블라디미르', '볼리베어', '워윅', '자야', '제라스', '신 짜오', '야스오', '요네', '요릭', '유미', '자크', '제드', '제리', '직스', '질리언', '조이', '자이라']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_champion_names(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)  # CSV 읽기\n",
    "    return df[\"name\"].tolist()  # 'name' 열을 리스트로 변환\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = \"./Champion_list.csv\"\n",
    "champion_names = extract_champion_names(file_path)\n",
    "print(champion_names)\n",
    "# 출력: ['아트록스', '아리', '이즈리얼', '쓰레쉬', .....]\n",
    "# 리그오브레전드의 모든 챔피언들의 이름을 불러온다..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': '미드', 'champion': '아리'}\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "\n",
    "roles = [\"탑\", \"정글\", \"미드\", \"원딜\", \"서폿\"]\n",
    "\n",
    "# 형태소 분석기 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 역할과 챔피언 이름 추출 함수\n",
    "def extract_entities(sentence):\n",
    "    # 형태소 분석\n",
    "    morphs = okt.morphs(sentence)\n",
    "\n",
    "    # 역할과 챔피언 이름 초기화\n",
    "    extracted_role = None\n",
    "    extracted_champion = None\n",
    "\n",
    "    # 형태소 중에서 역할과 챔피언 이름을 찾음\n",
    "    for word in morphs:\n",
    "        if word in roles:\n",
    "            extracted_role = word\n",
    "        if word in champion_names:\n",
    "            extracted_champion = word\n",
    "\n",
    "    return {\"role\": extracted_role, \"champion\": extracted_champion}\n",
    "\n",
    "# 테스트 문장\n",
    "question = \"미드 아리 아이템 알려줘\"\n",
    "entities = extract_entities(question)\n",
    "print(entities)\n",
    "# 출력 예시: {'role': '탑', 'champion': '아트록스'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_item_info(item_data, role, champion):\n",
    "    if 'error' in item_data:\n",
    "        return item_data['error']\n",
    "    \n",
    "    # 역할과 챔피언을 포함한 동적 메시지 생성\n",
    "    response = f\"챔피언 {champion} ({role})에 대한 추천 아이템과 룬을 안내해 드리겠습니다.\\n\"\n",
    "\n",
    "    # 주 룬 포맷팅\n",
    "    primary_runes = \"주 룬: \" + \", \".join([f\"{rune['name']} ({rune['category']})\" for rune in item_data['labeledPrimaryRunes']])\n",
    "    response += primary_runes + \"\\n\"\n",
    "    \n",
    "    # 부 룬 포맷팅\n",
    "    sub_runes = \"부 룬: \" + \", \".join([f\"{rune['name']} ({rune['category']})\" for rune in item_data['labeledSubRunes']])\n",
    "    response += sub_runes + \"\\n\"\n",
    "    \n",
    "    # 추천 아이템 포맷팅\n",
    "    items = \"추천 아이템: \" + \", \".join([item['name'] for item in item_data['labeledItems']])\n",
    "    response += items\n",
    "\n",
    "    return response\n",
    "\n",
    "def format_user_stats(stats_data):\n",
    "    # stats_data가 리스트 형태일 경우 처리\n",
    "    if isinstance(stats_data, list):\n",
    "        # 각 챔피언의 전적 정보를 포맷팅하여 출력\n",
    "        response = \"전적 정보에 대해 알려 드리겠습니다!!\\n\"\n",
    "        for stat in stats_data:\n",
    "            if 'championName' in stat:\n",
    "                response += f\"\\n챔피언: {stat.get('championName', '정보 없음')}\\n\"\n",
    "                response += f\"킬: {stat.get('kills', '정보 없음')}\\n\"\n",
    "                response += f\"데스: {stat.get('deaths', '정보 없음')}\\n\"\n",
    "                response += f\"어시스트: {stat.get('assists', '정보 없음')}\\n\"\n",
    "                response += f\"딜량: {stat.get('dealt', '정보 없음')}\\n\"\n",
    "                response += f\"피해량: {stat.get('taken', '정보 없음')}\\n\"\n",
    "                response += f\"딜량/분: {stat.get('dealt_per_minute', '정보 없음')}\\n\"\n",
    "                response += f\"피해량/분: {stat.get('taken_per_minute', '정보 없음')}\\n\"\n",
    "                response += f\"딜량/피해량 비율: {stat.get('dealt_per_taken', '정보 없음')}\\n\"\n",
    "                response += f\"시야: {stat.get('vision', '정보 없음')}\\n\"\n",
    "                response += f\"힐: {stat.get('heal', '정보 없음')}\\n\"\n",
    "                response += f\"CS: {stat.get('cs', '정보 없음')}\\n\"\n",
    "                response += f\"게임 시간(초): {stat.get('duration', '정보 없음')}\\n\"\n",
    "            else:\n",
    "                response += \"잘못된 데이터 형식입니다.\"\n",
    "        return response\n",
    "    else:\n",
    "        return \"전적 데이터 형식이 잘못되었습니다.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from konlpy.tag import Okt\n",
    "from retrying import retry\n",
    "import re\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "item_keywords = [\"아이템\"]\n",
    "stat_keywords = [\"전적\", \"승률\"]\n",
    "\n",
    "# API 예시 URL들 (실제 API URL로 교체 필요)\n",
    "stat_api_url = \"http://localhost:3000/summonerInfo\"\n",
    "item_api_url = \"http://localhost:3000/getChampInfo\"\n",
    "\n",
    "winrate_api_url = \"https://api.example.com/winrate\" #승률예측 부분 api는 서버에 올리기 번거로움 tensorflow를 챗봇에게 내장시킬 예정\n",
    "\n",
    "def get_item_info(position, champion):\n",
    "    url = f\"{item_api_url}/{position}/{champion}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=20)  # 10초 동안 기다림\n",
    "        if response.status_code == 200:\n",
    "            return response.json()  # 아이템 리스트 반환\n",
    "        return {\"error\": f\"Failed to fetch item info: {response.status_code}\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        return {\"error\": \"Request timed out\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def get_user_stats(nickname, tag):\n",
    "    url = f\"{stat_api_url}/{nickname}/{tag}\"\n",
    "    try:\n",
    "        # 요청에 10초 타임아웃 설정\n",
    "        response = requests.get(url, timeout=20)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()  # 유저 전적 정보 반환\n",
    "        return {\"error\": f\"Failed to fetch user stats: {response.status_code}\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        return {\"error\": \"Request timed out\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}  # 기타 네트워크 에러 처리\n",
    "\n",
    "def get_winrate(champion):\n",
    "    response = requests.get(winrate_api_url, params={\"champion\": champion})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # 승률 정보 반환\n",
    "    return {}\n",
    "\n",
    "# 역할, 챔피언, 아이템, 닉네임, 태그 추출 함수\n",
    "def extract_entities(sentence):\n",
    "    morphs = okt.morphs(sentence)\n",
    "\n",
    "    extracted_role = None\n",
    "    extracted_champion = None\n",
    "    extracted_item = None\n",
    "    extracted_stat = None\n",
    "    extracted_nickname = None\n",
    "    extracted_tag = None\n",
    "\n",
    "    # 닉네임#태그 형식 추출 (정규 표현식 사용)\n",
    "    match = re.search(r\"(\\S+)#(\\S+)\", sentence)\n",
    "    if match:\n",
    "        extracted_nickname = match.group(1)  # 닉네임\n",
    "        extracted_tag = match.group(2)       # 태그\n",
    "\n",
    "    # 형태소 중에서 역할과 챔피언 이름을 찾음\n",
    "    for word in morphs:\n",
    "        if word in roles:\n",
    "            extracted_role = word\n",
    "        if word in champion_names:\n",
    "            extracted_champion = word\n",
    "        if word in item_keywords:\n",
    "            extracted_item = word\n",
    "        if word in stat_keywords:\n",
    "            extracted_stat = word\n",
    "\n",
    "    return {\"role\": extracted_role, \"champion\": extracted_champion, \"item\": extracted_item, \"stat\": extracted_stat, \"nickname\": extracted_nickname, \"tag\": extracted_tag}\n",
    "\n",
    "# 유저 질문을 분석하여 API 호출\n",
    "def handle_user_question(question):\n",
    "    # 질문에서 역할과 챔피언 추출\n",
    "    entities = extract_entities(question)\n",
    "    role = entities['role']\n",
    "    champion = entities['champion']\n",
    "    \n",
    "    if entities[\"item\"]:\n",
    "        if role and champion:\n",
    "            # 아이템 정보 API 호출\n",
    "            item_data = get_item_info(role, champion)\n",
    "            # 데이터 포맷팅\n",
    "            formatted_response = format_item_info(item_data, role, champion)\n",
    "            return formatted_response\n",
    "        else:\n",
    "            return \"유효한 역할이나 챔피언 정보가 없습니다.\"\n",
    "\n",
    "    elif entities[\"stat\"]:\n",
    "        # 전적 API 호출 (닉네임#태그 형식 확인)\n",
    "        if entities[\"nickname\"] and entities[\"tag\"]:\n",
    "            stats = get_user_stats(entities[\"nickname\"], entities[\"tag\"])\n",
    "            formatted_stats = format_user_stats(stats)\n",
    "            return formatted_stats\n",
    "    \n",
    "    elif \"승률\" in entities[\"stat\"]:\n",
    "        if champion:\n",
    "            # 승률 API 호출\n",
    "            winrate = get_winrate(champion)\n",
    "            return f\"{champion} 챔피언의 승률: {winrate.get('winrate', '정보 없음')}%\"\n",
    "    \n",
    "    else:\n",
    "        return \"알 수 없는 질문입니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 자동으로 질문-응답 데이터 저장하는 함수\n",
    "def save_question_answer(question, answer):\n",
    "    data = {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    \n",
    "    # 데이터가 저장될 파일 경로\n",
    "    file_path = 'qa_dataset.json'\n",
    "    \n",
    "    # 기존 데이터 불러오기\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            qa_data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        qa_data = []\n",
    "    \n",
    "    # 새로운 데이터 추가\n",
    "    qa_data.append(data)\n",
    "    \n",
    "    # JSON 데이터를 UTF-8 인코딩으로 저장\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(qa_data, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_create(question):\n",
    "    response = handle_user_question(question)\n",
    "    save_question_answer(question, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챔피언 아트록스 (탑)에 대한 추천 아이템과 룬을 안내해 드리겠습니다.\n",
      "주 룬: 정복자 (정밀), 승전보 (전설), 전설: 가속 (전설), 최후의 저항 (결단)\n",
      "부 룬: 뼈 방패 (결의), 소생 (결의)\n",
      "추천 아이템: 칠흑의 양날 도끼, 선혈포식자, 드락사르의 황혼검, 헤르메스의 발걸음, 예언자의 렌즈\n",
      "챔피언 아리 (미드)에 대한 추천 아이템과 룬을 안내해 드리겠습니다.\n",
      "주 룬: 감전 (지배), 피의 맛 (지배), 사냥의 증표 (지배), 궁극의 사냥꾼 (지배)\n",
      "부 룬: 마나순환 팔찌 (마법), 깨달음 (마법)\n",
      "추천 아이템: 마법사의 신발, 도란의 반지, 만년서리, 그림자불꽃, 존야의 모래시계, 망원형 개조\n"
     ]
    }
   ],
   "source": [
    "# 테스트 1: \"탑 아트록스 아이템 알려줘\"\n",
    "question1 = \"탑 아트록스 아이템 알려줘\"\n",
    "response1 = handle_user_question(question1)\n",
    "save_question_answer(question1, response1)\n",
    "print(response1)\n",
    "\n",
    "# 테스트 2: \"미드 아리 아이템 알려줘\"\n",
    "question2 = \"미드 아리 아이템 알려줘\"\n",
    "response2 = handle_user_question(question2)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전적 정보:\n",
      "\n",
      "챔피언: Ekko\n",
      "킬: 8\n",
      "데스: 9\n",
      "어시스트: 11\n",
      "딜량: 10111\n",
      "피해량: 13320\n",
      "딜량/분: 677.83\n",
      "피해량/분: 892.96\n",
      "딜량/피해량 비율: 0.76\n",
      "시야: 0\n",
      "힐: 1169\n",
      "CS: 13\n",
      "게임 시간(초): 895\n",
      "\n",
      "챔피언: Taliyah\n",
      "킬: 6.5\n",
      "데스: 5\n",
      "어시스트: 17.5\n",
      "딜량: 41171\n",
      "피해량: 23001\n",
      "딜량/분: 2141.2\n",
      "피해량/분: 1182.62\n",
      "딜량/피해량 비율: 1.84\n",
      "시야: 0\n",
      "힐: 790.5\n",
      "CS: 45\n",
      "게임 시간(초): 1160\n",
      "\n",
      "챔피언: Jhin\n",
      "킬: 6.5\n",
      "데스: 3\n",
      "어시스트: 8\n",
      "딜량: 25386.5\n",
      "피해량: 15206.5\n",
      "딜량/분: 1544.1\n",
      "피해량/분: 935.26\n",
      "딜량/피해량 비율: 1.66\n",
      "시야: 0\n",
      "힐: 3349.5\n",
      "CS: 43\n",
      "게임 시간(초): 978\n",
      "\n",
      "챔피언: Vi\n",
      "킬: 3\n",
      "데스: 7\n",
      "어시스트: 6\n",
      "딜량: 8462\n",
      "피해량: 13160\n",
      "딜량/분: 952.57\n",
      "피해량/분: 1481.43\n",
      "딜량/피해량 비율: 0.64\n",
      "시야: 0\n",
      "힐: 1684\n",
      "CS: 15\n",
      "게임 시간(초): 533\n",
      "\n",
      "챔피언: Ambessa\n",
      "킬: 6.5\n",
      "데스: 5\n",
      "어시스트: 6\n",
      "딜량: 24242\n",
      "피해량: 32389.5\n",
      "딜량/분: 1588.09\n",
      "피해량/분: 2124.9\n",
      "딜량/피해량 비율: 0.75\n",
      "시야: 0\n",
      "힐: 7140.5\n",
      "CS: 27.5\n",
      "게임 시간(초): 912.5\n",
      "\n",
      "챔피언: Caitlyn\n",
      "킬: 8\n",
      "데스: 7\n",
      "어시스트: 14\n",
      "딜량: 17228\n",
      "피해량: 11722\n",
      "딜량/분: 1719.93\n",
      "피해량/분: 1170.25\n",
      "딜량/피해량 비율: 1.47\n",
      "시야: 0\n",
      "힐: 1038\n",
      "CS: 23\n",
      "게임 시간(초): 601\n",
      "\n",
      "챔피언: Ashe\n",
      "킬: 5\n",
      "데스: 4.33\n",
      "어시스트: 12.33\n",
      "딜량: 39871.33\n",
      "피해량: 28023.33\n",
      "딜량/분: 1741.08\n",
      "피해량/분: 1178.49\n",
      "딜량/피해량 비율: 1.58\n",
      "시야: 3\n",
      "힐: 5824.33\n",
      "CS: 103.67\n",
      "게임 시간(초): 1330.67\n",
      "\n",
      "챔피언: Gwen\n",
      "킬: 8\n",
      "데스: 9\n",
      "어시스트: 15\n",
      "딜량: 27975\n",
      "피해량: 29259\n",
      "딜량/분: 1723.31\n",
      "피해량/분: 1802.4\n",
      "딜량/피해량 비율: 0.96\n",
      "시야: 0\n",
      "힐: 8900\n",
      "CS: 49\n",
      "게임 시간(초): 974\n",
      "\n",
      "챔피언: Zed\n",
      "킬: 33\n",
      "데스: 15\n",
      "어시스트: 8\n",
      "딜량: 54225\n",
      "피해량: 32966\n",
      "딜량/분: 2561.81\n",
      "피해량/분: 1557.45\n",
      "딜량/피해량 비율: 1.64\n",
      "시야: 0\n",
      "힐: 2131\n",
      "CS: 35\n",
      "게임 시간(초): 1270\n",
      "\n",
      "챔피언: Shaco\n",
      "킬: 17\n",
      "데스: 14\n",
      "어시스트: 7\n",
      "딜량: 21943\n",
      "피해량: 23061\n",
      "딜량/분: 1259.89\n",
      "피해량/분: 1324.08\n",
      "딜량/피해량 비율: 0.95\n",
      "시야: 0\n",
      "힐: 866\n",
      "CS: 15\n",
      "게임 시간(초): 1045\n",
      "\n",
      "챔피언: Graves\n",
      "킬: 14\n",
      "데스: 11\n",
      "어시스트: 12\n",
      "딜량: 24277\n",
      "피해량: 22444\n",
      "딜량/분: 1484.83\n",
      "피해량/분: 1372.72\n",
      "딜량/피해량 비율: 1.08\n",
      "시야: 0\n",
      "힐: 3534\n",
      "CS: 42\n",
      "게임 시간(초): 981\n",
      "\n",
      "챔피언: Yasuo\n",
      "킬: 11\n",
      "데스: 10\n",
      "어시스트: 15\n",
      "딜량: 16492\n",
      "피해량: 18826\n",
      "딜량/분: 1393.69\n",
      "피해량/분: 1590.93\n",
      "딜량/피해량 비율: 0.88\n",
      "시야: 0\n",
      "힐: 3693\n",
      "CS: 45\n",
      "게임 시간(초): 710\n",
      "\n",
      "챔피언: Blitzcrank\n",
      "킬: 8\n",
      "데스: 6\n",
      "어시스트: 13\n",
      "딜량: 13947\n",
      "피해량: 18350\n",
      "딜량/분: 942.36\n",
      "피해량/분: 1239.86\n",
      "딜량/피해량 비율: 0.76\n",
      "시야: 0\n",
      "힐: 1308\n",
      "CS: 15\n",
      "게임 시간(초): 888\n",
      "\n",
      "챔피언: Diana\n",
      "킬: 5\n",
      "데스: 10\n",
      "어시스트: 11\n",
      "딜량: 16125\n",
      "피해량: 18673\n",
      "딜량/분: 1008.86\n",
      "피해량/분: 1168.28\n",
      "딜량/피해량 비율: 0.86\n",
      "시야: 0\n",
      "힐: 590\n",
      "CS: 50\n",
      "게임 시간(초): 959\n",
      "\n",
      "챔피언: Orianna\n",
      "킬: 1\n",
      "데스: 5\n",
      "어시스트: 6\n",
      "딜량: 7518\n",
      "피해량: 6944\n",
      "딜량/분: 852.7\n",
      "피해량/분: 787.6\n",
      "딜량/피해량 비율: 1.08\n",
      "시야: 0\n",
      "힐: 111\n",
      "CS: 28\n",
      "게임 시간(초): 529\n",
      "\n",
      "챔피언: Malzahar\n",
      "킬: 4\n",
      "데스: 11\n",
      "어시스트: 35\n",
      "딜량: 24667\n",
      "피해량: 29201\n",
      "딜량/분: 1289.22\n",
      "피해량/분: 1526.18\n",
      "딜량/피해량 비율: 0.84\n",
      "시야: 0\n",
      "힐: 1573\n",
      "CS: 74\n",
      "게임 시간(초): 1148\n",
      "\n",
      "챔피언: Katarina\n",
      "킬: 12\n",
      "데스: 9\n",
      "어시스트: 6\n",
      "딜량: 19032\n",
      "피해량: 20364\n",
      "딜량/분: 1223.92\n",
      "피해량/분: 1309.58\n",
      "딜량/피해량 비율: 0.93\n",
      "시야: 0\n",
      "힐: 2578\n",
      "CS: 23\n",
      "게임 시간(초): 933\n",
      "\n",
      "챔피언: Jinx\n",
      "킬: 15\n",
      "데스: 7\n",
      "어시스트: 26\n",
      "딜량: 33601\n",
      "피해량: 16660\n",
      "딜량/분: 2174.82\n",
      "피해량/분: 1078.32\n",
      "딜량/피해량 비율: 2.02\n",
      "시야: 0\n",
      "힐: 2622\n",
      "CS: 74\n",
      "게임 시간(초): 927\n",
      "\n",
      "챔피언: Akshan\n",
      "킬: 13\n",
      "데스: 12\n",
      "어시스트: 22\n",
      "딜량: 35809\n",
      "피해량: 26542\n",
      "딜량/분: 1627.68\n",
      "피해량/분: 1206.45\n",
      "딜량/피해량 비율: 1.35\n",
      "시야: 0\n",
      "힐: 1742\n",
      "CS: 77\n",
      "게임 시간(초): 1320\n",
      "\n",
      "챔피언: Viktor\n",
      "킬: 19\n",
      "데스: 7\n",
      "어시스트: 16\n",
      "딜량: 29197\n",
      "피해량: 16022\n",
      "딜량/분: 1824.81\n",
      "피해량/분: 1001.38\n",
      "딜량/피해량 비율: 1.82\n",
      "시야: 0\n",
      "힐: 2103\n",
      "CS: 55\n",
      "게임 시간(초): 960\n",
      "\n",
      "챔피언: Ahri\n",
      "킬: 12\n",
      "데스: 10\n",
      "어시스트: 23\n",
      "딜량: 37400\n",
      "피해량: 25916\n",
      "딜량/분: 2083.57\n",
      "피해량/분: 1443.79\n",
      "딜량/피해량 비율: 1.44\n",
      "시야: 0\n",
      "힐: 7057\n",
      "CS: 77\n",
      "게임 시간(초): 1077\n",
      "\n",
      "챔피언: LeeSin\n",
      "킬: 13\n",
      "데스: 8\n",
      "어시스트: 15\n",
      "딜량: 22514\n",
      "피해량: 23038\n",
      "딜량/분: 1511.01\n",
      "피해량/분: 1546.17\n",
      "딜량/피해량 비율: 0.98\n",
      "시야: 0\n",
      "힐: 6156\n",
      "CS: 18\n",
      "게임 시간(초): 894\n",
      "\n",
      "챔피언: Sion\n",
      "킬: 20\n",
      "데스: 20\n",
      "어시스트: 39\n",
      "딜량: 67883\n",
      "피해량: 142853\n",
      "딜량/분: 2236.67\n",
      "피해량/분: 4706.85\n",
      "딜량/피해량 비율: 0.48\n",
      "시야: 0\n",
      "힐: 9942\n",
      "CS: 149\n",
      "게임 시간(초): 1821\n",
      "\n",
      "챔피언: Lux\n",
      "킬: 5\n",
      "데스: 2\n",
      "어시스트: 22\n",
      "딜량: 12044\n",
      "피해량: 4506\n",
      "딜량/분: 1013.52\n",
      "피해량/분: 379.19\n",
      "딜량/피해량 비율: 2.67\n",
      "시야: 0\n",
      "힐: 548\n",
      "CS: 31\n",
      "게임 시간(초): 713\n",
      "\n",
      "챔피언: Zoe\n",
      "킬: 12\n",
      "데스: 8\n",
      "어시스트: 22\n",
      "딜량: 39591\n",
      "피해량: 21484\n",
      "딜량/분: 2111.52\n",
      "피해량/분: 1145.81\n",
      "딜량/피해량 비율: 1.84\n",
      "시야: 0\n",
      "힐: 1814\n",
      "CS: 43\n",
      "게임 시간(초): 1125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question1 = \"조선제일GUM#KR 전적 알려줘\"\n",
    "response1 = handle_user_question(question1)\n",
    "print(response1)  # 전적 정보 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': '탑 아트록스 아이템 알려줘', 'answer': '챔피언 아트록스 (탑)에 대한 추천 아이템과 룬을 안내해 드리겠습니다.\\n주 룬: 정복자 (정밀), 승전보 (전설), 전설: 가속 (전설), 최후의 저항 (결단)\\n부 룬: 뼈 방패 (결의), 소생 (결의)\\n추천 아이템: 칠흑의 양날 도끼, 선혈포식자, 드락사르의 황혼검, 헤르메스의 발걸음, 예언자의 렌즈'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'C:/Users/dlehr/OneDrive/바탕 화면/lol_data/jupyter/qa_dataset.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "decapoda-research/llama-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/decapoda-research/llama-7b-hf/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 277\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    278\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    279\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    280\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 301\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m     )\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67461b77-056b7012665b7bc27774be7c;96e7f1a0-0456-42e6-be44-dbbf2f0b0410)\n\nRepository Not Found for url: https://huggingface.co/decapoda-research/llama-7b-hf/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LLaMA 모델과 토크나이저 로드\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecapoda-research/llama-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# LLaMA 7B 모델 (또는 다른 모델)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# eos_token을 pad_token으로 설정 (필요한 경우)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3506\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   3505\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m-> 3506\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3509\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3515\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3516\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3517\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3518\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3519\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3520\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3521\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   3522\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: decapoda-research/llama-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# LLaMA 모델과 토크나이저 로드\n",
    "model_name = \"decapoda-research/llama-7b-hf\"  # LLaMA 7B 모델 (또는 다른 모델)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# eos_token을 pad_token으로 설정 (필요한 경우)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # eos_token을 pad_token으로 설정\n",
    "\n",
    "# JSON 파일 경로\n",
    "file_path = './qa_dataset.json'\n",
    "\n",
    "# 데이터셋으로 변환\n",
    "dataset = Dataset.from_json(file_path)\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(examples):\n",
    "    # 질문과 응답을 하나로 합치고 토큰화 (문자열로 결합)\n",
    "    input_text = [str(q) + \" \" + tokenizer.eos_token + \" \" + str(a) for q, a in zip(examples['question'], examples['answer'])]\n",
    "    output_text = [str(a) + tokenizer.eos_token for a in examples['answer']]\n",
    "\n",
    "    # 토큰화\n",
    "    input_ids = tokenizer(input_text, truncation=True, padding='max_length', max_length=128, return_tensors=\"pt\").input_ids\n",
    "    labels = tokenizer(output_text, truncation=True, padding='max_length', max_length=128, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # 'input_ids'와 'labels'를 각각 리스트 형태로 반환\n",
    "    return {'input_ids': input_ids.tolist(), 'labels': labels.tolist()}\n",
    "\n",
    "# 데이터셋 전처리\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 학습 매개변수 설정\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# 학습 결과 저장 디렉토리\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 에폭마다 평가\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# 학습률\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 배치 크기\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 에폭 수\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 가중치 감소\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Trainer 설정\u001b[39;00m\n\u001b[0;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                  \u001b[38;5;66;03m# 학습할 모델\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,           \u001b[38;5;66;03m# 학습 매개변수\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,        \u001b[38;5;66;03m# 학습 데이터셋\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1773\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2299\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2298\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:60\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\dlehr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2172\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   2171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2173\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2175\u001b[0m         )\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# 학습 매개변수 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",          # 학습 결과 저장 디렉토리\n",
    "    evaluation_strategy=\"epoch\",    # 에폭마다 평가\n",
    "    learning_rate=2e-5,             # 학습률\n",
    "    per_device_train_batch_size=2,  # 배치 크기\n",
    "    num_train_epochs=3,            # 에폭 수\n",
    "    weight_decay=0.01,              # 가중치 감소\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,                  # 학습할 모델\n",
    "    args=training_args,           # 학습 매개변수\n",
    "    train_dataset=dataset,        # 학습 데이터셋\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 저장\n",
    "model.save_pretrained('./fine_tuned_gpt2')\n",
    "tokenizer.save_pretrained('./fine_tuned_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuned 모델과 토크나이저 로드\n",
    "fine_tuned_model = GPT2LMHeadModel.from_pretrained('./fine_tuned_gpt2')\n",
    "fine_tuned_tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_gpt2')\n",
    "\n",
    "# 모델 예측\n",
    "def generate_response(question):\n",
    "    input_ids = fine_tuned_tokenizer.encode(question + fine_tuned_tokenizer.eos_token, return_tensors='pt')\n",
    "    output = fine_tuned_model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    return fine_tuned_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 예시 질문에 대한 응답\n",
    "question = \"탑 아트록스 아이템 알려줘\"\n",
    "response = generate_response(question)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
